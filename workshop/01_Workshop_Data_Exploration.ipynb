{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be79e302-02ed-4c0d-bffd-9e700d4b834c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Workshop 1: Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Objective\n",
    "\n",
    "Perform exploratory data analysis to understand the RetailMax sales dataset and identify data quality issues before building an ML model.\n",
    "\n",
    "## Context and Requirements\n",
    "\n",
    "- **Workshop:** Customer Segmentation for RetailMax\n",
    "- **Notebook type:** Hands-on Exercise\n",
    "- **Prerequisites:** `00_Workshop_Setup.ipynb` completed\n",
    "- **Technical requirements:**\n",
    "  - Databricks Runtime 14.x LTS or newer\n",
    "  - Unity Catalog enabled\n",
    "- **Execution time:** ~30 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Theoretical Background\n",
    "\n",
    "**Why is EDA important for ML?**\n",
    "\n",
    "Exploratory Data Analysis is the first step in any ML project. The \"Garbage In, Garbage Out\" principle means that even the best model cannot compensate for poor data quality.\n",
    "\n",
    "**EDA helps answer:**\n",
    "\n",
    "| Aspect | Question | Impact on ML |\n",
    "|--------|----------|--------------|\n",
    "| **Data Quality** | Missing values? Duplicates? Invalid values? | Requires imputation or removal |\n",
    "| **Distribution** | Normal or skewed? | Affects model choice and scaling |\n",
    "| **Outliers** | Extreme values present? | Can distort linear models |\n",
    "| **Correlations** | Which features are related? | Informs feature selection |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6fc102e-84ae-4347-85f5-bbfa3369fba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../demo/00_Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ca19894-6627-4398-85e6-d156f81cbb1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb32d2c6-34a2-4f6e-8077-d3759df4c8bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1: Load Data\n",
    "# Load the 'workshop_sales_data' table into a DataFrame named 'df'.\n",
    "# Display the row count and first 5 records to verify the data loaded correctly.\n",
    "\n",
    "df = # TODO: Load table\n",
    "# print(...)\n",
    "# display(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4dda275e-2e76-4c69-86cc-dd69b0ac25c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 2: Data Profiling\n",
    "\n",
    "Before cleaning, understand the nature of the data.\n",
    "\n",
    "**Check:**\n",
    "1. **Data types:** Are dates stored as dates? Are numbers numeric?\n",
    "2. **Statistics:** Do mean values make sense? Are there outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "899e4053-802c-4295-8944-3844c3d547bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 2: Display the data schema\n",
    "# Pay attention to columns: 'order_datetime', 'quantity', 'total_amount'. Are their types correct?\n",
    "\n",
    "# TODO: Print schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75156861-9210-4660-a301-b4850ce72ce7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3: Display summary statistics for numeric columns\n",
    "# Columns: 'quantity', 'unit_cost', 'sales_price', 'total_amount'\n",
    "# Check MIN and MAX values. Do you see anything concerning (negative prices, extreme quantities)?\n",
    "\n",
    "# TODO: Display summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5d4e123-a245-480c-8d02-70d1e0bb88c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3b: Check skewness of numeric columns\n",
    "# Skewness > 1 or < -1 indicates highly skewed data\n",
    "# Highly skewed features may need Log Transformation before modeling\n",
    "\n",
    "from pyspark.sql.functions import skewness\n",
    "\n",
    "# TODO: Calculate skewness for 'total_amount' and 'quantity'\n",
    "# Hint: df.select(skewness(\"column_name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da5bfc85-e08b-4e50-a5d0-96b1b7ae4423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 3: Data Quality Issue Identification\n",
    "\n",
    "Real-world data is rarely perfect. Identify specific issues to plan remediation.\n",
    "\n",
    "**Look for:**\n",
    "1. **Missing values (Nulls):** Which columns are incomplete?\n",
    "2. **Logical errors:** Negative quantities, negative prices\n",
    "3. **Inconsistencies:** Does `quantity * sales_price` equal `total_amount`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33d9921c-3583-430d-bb41-c754a7e268ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, isnan, round, abs\n",
    "\n",
    "# Exercise 4: Count NULL values in each column\n",
    "# Hint: Use a loop over df.columns or list comprehension\n",
    "\n",
    "null_counts = # TODO: Count nulls per column\n",
    "display(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3203a8d4-c0a0-4b26-a91d-4e10b5abec2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 5: Check for logical errors\n",
    "# Find rows where:\n",
    "# a) 'quantity' is less than or equal to 0\n",
    "# b) 'total_amount' is less than 0\n",
    "# Display the invalid records\n",
    "\n",
    "invalid_orders = # TODO: Filter invalid orders\n",
    "# print(...)\n",
    "display(invalid_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "236502e4-2da2-4ff6-9bf8-36569113e35e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 6 (Challenge): Check mathematical consistency\n",
    "# Does 'total_amount' equal 'quantity' * 'sales_price'?\n",
    "# Account for floating point precision (difference > 0.01)\n",
    "# Find records where the calculation does not match\n",
    "\n",
    "inconsistent_prices = # TODO: Find inconsistent records\n",
    "\n",
    "# print(...)\n",
    "# display(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ceab2df0-7ff7-45d6-8888-817ba8167b22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 4: Distribution Analysis\n",
    "\n",
    "Visualizations help identify trends and anomalies quickly.\n",
    "\n",
    "**Focus on:**\n",
    "1. Payment method distribution\n",
    "2. Customer segment distribution\n",
    "3. Sales over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92613b2d-6e5f-4afa-8815-6b2e401b1126",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 7: Visualize 'payment_method' distribution\n",
    "# Use display() on grouped data. Which payment method is most common?\n",
    "\n",
    "# TODO: Group and display payment methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4aeb2d4d-b0db-40d3-822a-cb96f37f5d21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 8: Visualize 'customer_segment' distribution\n",
    "# Are the classes balanced or does one segment dominate? This is important for the ML model.\n",
    "\n",
    "# TODO: Group and display customer segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0807c65a-6096-42b9-8981-408fd06d9d7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Checkpoint\n",
    "\n",
    "At this point, you should have:\n",
    "- Loaded and examined the dataset structure\n",
    "- Identified null values and their distribution\n",
    "- Found logical errors (negative quantities, amounts)\n",
    "- Checked skewness of numeric features\n",
    "- Analyzed class balance in customer segments\n",
    "\n",
    "**Key findings to address in the next notebook:**\n",
    "- Missing values in key columns\n",
    "- Invalid records (negative values)\n",
    "- Mathematical inconsistencies\n",
    "- Skewed distributions (may need log transform)\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices: EDA\n",
    "\n",
    "| Practice | Description |\n",
    "|----------|-------------|\n",
    "| **Start with shape** | `df.count()`, `len(df.columns)` before anything else |\n",
    "| **Check types first** | `printSchema()` - wrong types cause silent errors |\n",
    "| **Use summary()** | Quick view of min/max reveals impossible values |\n",
    "| **Check skewness** | Values > 1 need transformation (log, sqrt) |\n",
    "| **Document findings** | Write down issues for the cleaning phase |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3b862cd-2cad-48ca-a7c0-cee144662c98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Solutions\n",
    "\n",
    "Reference solutions for the exercises above. Compare your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbc6b172-84b5-47fe-9b06-1ab3cc4e6184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Load Data\n",
    "df = spark.table(\"workshop_sales_data\")\n",
    "print(f\"Rows: {df.count()}\")\n",
    "display(df.limit(5))\n",
    "\n",
    "# 2. Schema\n",
    "df.printSchema()\n",
    "\n",
    "# 3. Stats\n",
    "display(df.select(\"quantity\", \"unit_cost\", \"sales_price\", \"total_amount\").summary())\n",
    "\n",
    "# 3b. Skewness\n",
    "from pyspark.sql.functions import skewness\n",
    "display(df.select(\n",
    "    skewness(\"total_amount\").alias(\"total_amount_skew\"),\n",
    "    skewness(\"quantity\").alias(\"quantity_skew\")\n",
    "))\n",
    "\n",
    "# 4. Nulls\n",
    "from pyspark.sql.functions import col, count, when, abs, round\n",
    "null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "display(null_counts)\n",
    "\n",
    "# 5. Invalid Logic\n",
    "invalid_orders = df.filter((col(\"quantity\") <= 0) | (col(\"total_amount\") < 0))\n",
    "display(invalid_orders)\n",
    "\n",
    "# 6. Math Consistency\n",
    "inconsistent = df.withColumn(\"calc_total\", round(col(\"quantity\") * col(\"sales_price\"), 2)) \\\n",
    "                 .filter(abs(col(\"calc_total\") - col(\"total_amount\")) > 0.01)\n",
    "display(inconsistent)\n",
    "\n",
    "# 7 & 8. Visualizations\n",
    "display(df.groupBy(\"payment_method\").count())\n",
    "display(df.groupBy(\"customer_segment\").count())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Workshop_Data_Exploration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
