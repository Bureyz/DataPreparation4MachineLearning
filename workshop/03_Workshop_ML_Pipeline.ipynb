{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "315ed1a0-4e5b-4f42-aecf-5667064729aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Workshop 3: ML Pipeline with MLflow\n",
    "\n",
    "## Objective\n",
    "\n",
    "Build a complete ML pipeline for customer segmentation using Spark ML and track experiments with MLflow. Register the model in Unity Catalog for governance and versioning.\n",
    "\n",
    "## Context and Requirements\n",
    "\n",
    "- **Workshop:** Customer Segmentation for RetailMax\n",
    "- **Notebook type:** Hands-on Exercise\n",
    "- **Prerequisites:** `02_Workshop_Data_Cleaning_and_Features.ipynb` completed\n",
    "- **Technical requirements:**\n",
    "  - Databricks Runtime 14.x LTS or newer\n",
    "  - Unity Catalog enabled\n",
    "  - MLflow enabled (default in Databricks)\n",
    "- **Execution time:** ~30 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Theoretical Background\n",
    "\n",
    "**Why use Pipelines?**\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **Data Leakage Prevention** | `fit()` on train, `transform()` on test - automatic |\n",
    "| **Reproducibility** | Single artifact contains all preprocessing + model |\n",
    "| **Simplicity** | Save/load entire workflow as one object |\n",
    "| **Consistency** | Same transformations in training and production |\n",
    "\n",
    "**Pipeline Components:**\n",
    "\n",
    "```\n",
    "Data -> [Imputer] -> [Assembler] -> [Scaler] -> [Model] -> Predictions\n",
    "```\n",
    "\n",
    "**Unity Catalog Models (recommended):**\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Model Registry** | `catalog.schema.model_name` format |\n",
    "| **Versioning** | Automatic version tracking (v1, v2, ...) |\n",
    "| **Aliases** | `@champion`, `@challenger` for deployment |\n",
    "| **Governance** | Unity Catalog permissions apply |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33382c31-f842-4494-852d-36d6f5a66266",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../demo/00_Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "573a7478-fdd0-430d-a598-a69fd1a510ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 1: Load Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "424851c0-bb27-422d-89fd-846a61b146ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Environment setup (same as Workshop Setup)\n",
    "current_user_email = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "username = current_user_email.split(\"@\")[0].replace(\".\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "if \"trainer\" in username or \"krzysztof_burejza\" in username:\n",
    "    effective_user = \"trainer\"\n",
    "else:\n",
    "    effective_user = username\n",
    "\n",
    "catalog_name = \"data_ml_preparation\"\n",
    "schema_name = f\"ml_dp_{effective_user}\"\n",
    "\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "\n",
    "print(f\"Using: {catalog_name}.{schema_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75a50852-3a2b-4054-861d-72f150d6a827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load customer features from previous workshop\n",
    "df_features = spark.table(\"workshop_customer_features\")\n",
    "display(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8104c479-a76c-4d2c-bd49-470ebece7ddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 2: Data Splitting\n",
    "\n",
    "Split data into training (80%) and testing (20%) sets.\n",
    "\n",
    "**Important:** For imbalanced datasets, use stratified sampling to preserve class distribution in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e8dc9b5-73cd-4df5-a84f-6c7ff9ad44e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1: Split data into training (80%) and testing (20%) sets\n",
    "# Set seed=42 for reproducibility\n",
    "\n",
    "train_df, test_df = # TODO: Split data using randomSplit\n",
    "# print(f\"Train: {train_df.count()}, Test: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "663fe8b7-d386-4264-855a-0fd4bdc5dab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1b (Challenge): Stratified Split\n",
    "# Check class distribution before and after split\n",
    "# Use sampleBy() for stratified sampling if classes are imbalanced\n",
    "\n",
    "# Check distribution\n",
    "print(\"Full dataset distribution:\")\n",
    "display(df_features.groupBy(\"customer_segment\").count())\n",
    "\n",
    "# TODO: Verify that train and test have similar distributions\n",
    "# print(\"Train distribution:\")\n",
    "# display(train_df.groupBy(\"customer_segment\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46ebdc55-0a1a-4bff-9b19-9e063d80bf7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 3: Define ML Pipeline\n",
    "\n",
    "A Pipeline encapsulates a sequence of transformations into a single object. This is critical for reproducibility (same steps for training and inference).\n",
    "\n",
    "**Pipeline stages:**\n",
    "1. **Imputer:** Fill missing values in numeric features\n",
    "2. **Assembler:** Combine features into a single vector\n",
    "3. **Scaler:** Scale features (StandardScaler) so large values do not dominate\n",
    "4. **Indexer:** Convert text label (`customer_segment`) to numeric\n",
    "5. **Model:** Classifier (e.g., Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b824047-2447-434b-b49d-0e6d873362b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, Imputer\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "\n",
    "# 1. Label Indexer (Target: customer_segment)\n",
    "label_indexer = StringIndexer(inputCol=\"customer_segment\", outputCol=\"label\")\n",
    "\n",
    "# Exercise 2a: Define Imputer for columns 'total_spend', 'recency', 'tenure'\n",
    "imputer = # TODO: Create Imputer\n",
    "\n",
    "# Exercise 2b: Define VectorAssembler using imputed columns plus 'order_count' and 'country_index'\n",
    "assembler = # TODO: Create VectorAssembler\n",
    "\n",
    "# 4. Scaler\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
    "\n",
    "# Exercise 2c: Choose model (LogisticRegression or RandomForestClassifier)\n",
    "lr = # TODO: Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2971cb33-cd27-4d28-8ddb-827dafef421d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 3: Create Pipeline combining all stages\n",
    "\n",
    "pipeline = # TODO: Create Pipeline with all stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "709e5a1c-1c7f-4d8f-8426-1731eebb6b38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 4: Training, Evaluation, and Tuning with MLflow\n",
    "\n",
    "Track experiments and find optimal hyperparameters.\n",
    "\n",
    "**Tasks:**\n",
    "1. Start MLflow experiment run\n",
    "2. Log model parameters\n",
    "3. Calculate and log metrics (Accuracy, F1-Score)\n",
    "4. (Challenge) Use CrossValidator for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4174a45-56e9-4448-ab39-06f31e677982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Setup MLflow with Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Setup Experiment\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "experiment_path = f\"/Users/{username}/workshop_customer_segmentation\"\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "# Model name for Unity Catalog (uses catalog and schema from Workshop Setup)\n",
    "# These variables should be defined if you ran 00_Workshop_Setup.ipynb\n",
    "model_name = f\"{catalog_name}.{schema_name}.customer_segmentation_model\"\n",
    "\n",
    "# Exercise 4: Run MLflow experiment\n",
    "# Inside 'with mlflow.start_run():' block:\n",
    "# 1. Train pipeline on training set\n",
    "# 2. Make predictions on test set\n",
    "# 3. Calculate Accuracy and F1 Score\n",
    "# 4. Log metrics and register model to Unity Catalog\n",
    "\n",
    "# with mlflow.start_run(run_name=\"LR_Baseline\"):\n",
    "#     # Train\n",
    "#     model = pipeline.fit(train_df)\n",
    "#     \n",
    "#     # Predict\n",
    "#     predictions = model.transform(test_df)\n",
    "#     \n",
    "#     # Evaluate\n",
    "#     accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\").evaluate(predictions)\n",
    "#     mlflow.log_metric(\"accuracy\", accuracy)\n",
    "#     \n",
    "#     # Register model to Unity Catalog\n",
    "#     mlflow.spark.log_model(model, \"model\", registered_model_name=model_name)\n",
    "    \n",
    "# Exercise 4 (Challenge): Implement CrossValidation (Grid Search)\n",
    "# Create paramGrid for regParam (0.1, 0.01) and elasticNetParam (0.0, 0.5, 1.0)\n",
    "# Use CrossValidator with 3 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19657389-9a5f-47ee-a1bb-548450aee118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# Solutions\n",
    "\n",
    "Reference solutions for the exercises above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a31a642-b860-40e9-b391-419ccaf4fd6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Environment setup (same as Workshop Setup)\n",
    "current_user_email = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "username = current_user_email.split(\"@\")[0].replace(\".\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "if \"trainer\" in username or \"krzysztof_burejza\" in username:\n",
    "    effective_user = \"trainer\"\n",
    "else:\n",
    "    effective_user = username\n",
    "\n",
    "catalog_name = \"data_ml_preparation\"\n",
    "schema_name = f\"ml_dp_{effective_user}\"\n",
    "\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "\n",
    "print(f\"Using: {catalog_name}.{schema_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d22f9809-64f7-47a2-806e-f96adcb0504c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load customer features from previous workshop\n",
    "df_features = spark.table(\"workshop_customer_features\")\n",
    "display(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75d5b8e0-83d6-458b-8035-9ee27abd848d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Split\n",
    "train_df, test_df = df_features.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Train: {train_df.count()}, Test: {test_df.count()}\")\n",
    "\n",
    "# 1b. Verify distribution (stratification check)\n",
    "print(\"Train distribution:\")\n",
    "display(train_df.groupBy(\"customer_segment\").count())\n",
    "print(\"Test distribution:\")\n",
    "display(test_df.groupBy(\"customer_segment\").count())\n",
    "\n",
    "# 2. Pipeline Definition\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, Imputer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=\"customer_segment\", outputCol=\"label\")\n",
    "\n",
    "imputer = Imputer(inputCols=[\"total_spend\", \"recency\", \"tenure\"], outputCols=[\"total_spend_imp\", \"recency_imp\", \"tenure_imp\"])\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"total_spend_imp\", \"recency_imp\", \"tenure_imp\", \"order_count\", \"country_index\"], outputCol=\"features_raw\", handleInvalid='keep')\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[label_indexer, imputer, assembler, scaler, lr])\n",
    "\n",
    "# 3. MLflow with Unity Catalog & CrossValidation\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import mlflow\n",
    "\n",
    "# Setup Unity Catalog for model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "model_name = f\"{catalog_name}.{schema_name}.customer_segmentation_model\"\n",
    "\n",
    "with mlflow.start_run(run_name=\"LR_GridSearch\"):\n",
    "    # Grid\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "        .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "        .build()\n",
    "    \n",
    "    # CV\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\"),\n",
    "                              numFolds=3)\n",
    "    \n",
    "    # Fit\n",
    "    cvModel = crossval.fit(train_df)\n",
    "    \n",
    "    # Best Model Metrics\n",
    "    best_model = cvModel.bestModel\n",
    "    predictions = best_model.transform(test_df)\n",
    "    accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\").evaluate(predictions)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy_cv\", accuracy)\n",
    "    \n",
    "    # Register model to Unity Catalog\n",
    "    mlflow.spark.log_model(\n",
    "        best_model, \n",
    "        \"best_model\",\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Best CV Accuracy: {accuracy}\")\n",
    "    print(f\"Model registered to Unity Catalog: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dac9190-0b82-4978-9ba0-10510559a5b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "Workshop complete. The following has been achieved:\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| Data Splitting | 80/20 train/test split with seed for reproducibility |\n",
    "| Pipeline | Imputer -> Assembler -> Scaler -> Classifier |\n",
    "| MLflow Tracking | Experiment logged with params and metrics |\n",
    "| Unity Catalog Model | Model registered with governance and versioning |\n",
    "| Hyperparameter Tuning | CrossValidator with grid search |\n",
    "\n",
    "### Unity Catalog Artifacts Created:\n",
    "\n",
    "| Artifact | Location |\n",
    "|----------|----------|\n",
    "| Experiment | `/Users/{user}/workshop_customer_segmentation` |\n",
    "| Model | `{catalog}.{schema}.customer_segmentation_model` |\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices: ML Pipelines\n",
    "\n",
    "| Practice | Description |\n",
    "|----------|-------------|\n",
    "| **Use Pipelines** | Prevents data leakage, ensures reproducibility |\n",
    "| **Set random seed** | `seed=42` for reproducible splits |\n",
    "| **Stratify if imbalanced** | Preserve class distribution in splits |\n",
    "| **Use Unity Catalog Models** | Governance, versioning, lineage tracking |\n",
    "| **Log everything** | Params, metrics, and model artifacts to MLflow |\n",
    "| **Evaluate on holdout** | Final metric only from test set (never validation) |\n",
    "\n",
    "## Common Mistakes to Avoid\n",
    "\n",
    "| Mistake | Consequence |\n",
    "|---------|-------------|\n",
    "| Fitting scaler on all data | Data leakage - inflated metrics |\n",
    "| Using test set for tuning | Overfitting to test distribution |\n",
    "| Saving model locally | No governance, hard to share |\n",
    "| No random seed | Non-reproducible results |\n",
    "| Not logging to MLflow | Lost experiments, no comparison |\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- Set model alias `@champion` for production deployment\n",
    "- Deploy model for batch or real-time inference\n",
    "- Set up monitoring for model performance"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Workshop_ML_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
