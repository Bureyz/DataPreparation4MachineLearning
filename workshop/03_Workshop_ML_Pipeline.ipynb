{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134bb33e",
   "metadata": {},
   "source": [
    "# Workshop 3: ML Pipeline with MLflow\n",
    "\n",
    "## Objective\n",
    "\n",
    "Build a complete ML pipeline for customer segmentation using Spark ML and track experiments with MLflow. Register the model in Unity Catalog for governance and versioning.\n",
    "\n",
    "## Context and Requirements\n",
    "\n",
    "- **Workshop:** Customer Segmentation for RetailMax\n",
    "- **Notebook type:** Hands-on Exercise\n",
    "- **Prerequisites:** `02_Workshop_Data_Cleaning_and_Features.ipynb` completed\n",
    "- **Technical requirements:**\n",
    "  - Databricks Runtime 14.x LTS or newer\n",
    "  - Unity Catalog enabled\n",
    "  - MLflow enabled (default in Databricks)\n",
    "- **Execution time:** ~30 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## Theoretical Background\n",
    "\n",
    "**Why use Pipelines?**\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **Data Leakage Prevention** | `fit()` on train, `transform()` on test - automatic |\n",
    "| **Reproducibility** | Single artifact contains all preprocessing + model |\n",
    "| **Simplicity** | Save/load entire workflow as one object |\n",
    "| **Consistency** | Same transformations in training and production |\n",
    "\n",
    "**Pipeline Components:**\n",
    "\n",
    "```\n",
    "Data -> [Imputer] -> [Assembler] -> [Scaler] -> [Model] -> Predictions\n",
    "```\n",
    "\n",
    "**Unity Catalog Models (recommended):**\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Model Registry** | `catalog.schema.model_name` format |\n",
    "| **Versioning** | Automatic version tracking (v1, v2, ...) |\n",
    "| **Aliases** | `@champion`, `@challenger` for deployment |\n",
    "| **Governance** | Unity Catalog permissions apply |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af561bf9",
   "metadata": {},
   "source": [
    "## Section 1: Load Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b027b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customer features from previous workshop\n",
    "df_features = spark.table(\"workshop_customer_features\")\n",
    "display(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06563ba",
   "metadata": {},
   "source": [
    "## Section 2: Data Splitting\n",
    "\n",
    "Split data into training (80%) and testing (20%) sets.\n",
    "\n",
    "**Important:** For imbalanced datasets, use stratified sampling to preserve class distribution in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcac584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Split data into training (80%) and testing (20%) sets\n",
    "# Set seed=42 for reproducibility\n",
    "\n",
    "train_df, test_df = # TODO: Split data using randomSplit\n",
    "# print(f\"Train: {train_df.count()}, Test: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1b (Challenge): Stratified Split\n",
    "# Check class distribution before and after split\n",
    "# Use sampleBy() for stratified sampling if classes are imbalanced\n",
    "\n",
    "# Check distribution\n",
    "print(\"Full dataset distribution:\")\n",
    "display(df_features.groupBy(\"customer_segment\").count())\n",
    "\n",
    "# TODO: Verify that train and test have similar distributions\n",
    "# print(\"Train distribution:\")\n",
    "# display(train_df.groupBy(\"customer_segment\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83cdd04",
   "metadata": {},
   "source": [
    "## Section 3: Define ML Pipeline\n",
    "\n",
    "A Pipeline encapsulates a sequence of transformations into a single object. This is critical for reproducibility (same steps for training and inference).\n",
    "\n",
    "**Pipeline stages:**\n",
    "1. **Imputer:** Fill missing values in numeric features\n",
    "2. **Assembler:** Combine features into a single vector\n",
    "3. **Scaler:** Scale features (StandardScaler) so large values do not dominate\n",
    "4. **Indexer:** Convert text label (`customer_segment`) to numeric\n",
    "5. **Model:** Classifier (e.g., Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ae132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, Imputer\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "\n",
    "# 1. Label Indexer (Target: customer_segment)\n",
    "label_indexer = StringIndexer(inputCol=\"customer_segment\", outputCol=\"label\")\n",
    "\n",
    "# Exercise 2a: Define Imputer for columns 'total_spend', 'recency', 'tenure'\n",
    "imputer = # TODO: Create Imputer\n",
    "\n",
    "# Exercise 2b: Define VectorAssembler using imputed columns plus 'order_count' and 'country_index'\n",
    "assembler = # TODO: Create VectorAssembler\n",
    "\n",
    "# 4. Scaler\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
    "\n",
    "# Exercise 2c: Choose model (LogisticRegression or RandomForestClassifier)\n",
    "lr = # TODO: Create classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Create Pipeline combining all stages\n",
    "\n",
    "pipeline = # TODO: Create Pipeline with all stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05b974",
   "metadata": {},
   "source": [
    "## Section 4: Training, Evaluation, and Tuning with MLflow\n",
    "\n",
    "Track experiments and find optimal hyperparameters.\n",
    "\n",
    "**Tasks:**\n",
    "1. Start MLflow experiment run\n",
    "2. Log model parameters\n",
    "3. Calculate and log metrics (Accuracy, F1-Score)\n",
    "4. (Challenge) Use CrossValidator for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Setup Experiment\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "experiment_path = f\"/Users/{username}/workshop_customer_segmentation\"\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "# Exercise 4: Run MLflow experiment\n",
    "# Inside 'with mlflow.start_run():' block:\n",
    "# 1. Train pipeline on training set\n",
    "# 2. Make predictions on test set\n",
    "# 3. Calculate Accuracy and F1 Score\n",
    "# 4. Log metrics and model to MLflow\n",
    "\n",
    "# with mlflow.start_run(run_name=\"LR_Baseline\"):\n",
    "#     TODO: Implement training and logging\n",
    "    \n",
    "# Exercise 4 (Challenge): Implement CrossValidation (Grid Search)\n",
    "# Create paramGrid for regParam (0.1, 0.01) and elasticNetParam (0.0, 0.5, 1.0)\n",
    "# Use CrossValidator with 3 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc45f76",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Solutions\n",
    "\n",
    "Reference solutions for the exercises above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a4b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split\n",
    "train_df, test_df = df_features.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Train: {train_df.count()}, Test: {test_df.count()}\")\n",
    "\n",
    "# 1b. Verify distribution (stratification check)\n",
    "print(\"Train distribution:\")\n",
    "display(train_df.groupBy(\"customer_segment\").count())\n",
    "print(\"Test distribution:\")\n",
    "display(test_df.groupBy(\"customer_segment\").count())\n",
    "\n",
    "# 2. Pipeline Definition\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, Imputer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=\"customer_segment\", outputCol=\"label\")\n",
    "imputer = Imputer(inputCols=[\"total_spend\", \"recency\", \"tenure\"], outputCols=[\"total_spend_imp\", \"recency_imp\", \"tenure_imp\"])\n",
    "assembler = VectorAssembler(inputCols=[\"total_spend_imp\", \"recency_imp\", \"tenure_imp\", \"order_count\", \"country_index\"], outputCol=\"features_raw\")\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=[label_indexer, imputer, assembler, scaler, lr])\n",
    "\n",
    "# 3. MLflow & CrossValidation\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"LR_GridSearch\"):\n",
    "    # Grid\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "        .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "        .build()\n",
    "    \n",
    "    # CV\n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\"),\n",
    "                              numFolds=3)\n",
    "    \n",
    "    # Fit\n",
    "    cvModel = crossval.fit(train_df)\n",
    "    \n",
    "    # Best Model Metrics\n",
    "    best_model = cvModel.bestModel\n",
    "    predictions = best_model.transform(test_df)\n",
    "    accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\").evaluate(predictions)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy_cv\", accuracy)\n",
    "    mlflow.spark.log_model(best_model, \"best_model\")\n",
    "    print(f\"Best CV Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6718f0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Workshop complete. The following has been achieved:\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| Data Splitting | 80/20 train/test split with seed for reproducibility |\n",
    "| Pipeline | Imputer -> Assembler -> Scaler -> Classifier |\n",
    "| MLflow Tracking | Experiment logged with params and metrics |\n",
    "| Hyperparameter Tuning | CrossValidator with grid search |\n",
    "\n",
    "---\n",
    "\n",
    "## Best Practices: ML Pipelines\n",
    "\n",
    "| Practice | Description |\n",
    "|----------|-------------|\n",
    "| **Use Pipelines** | Prevents data leakage, ensures reproducibility |\n",
    "| **Set random seed** | `seed=42` for reproducible splits |\n",
    "| **Stratify if imbalanced** | Preserve class distribution in splits |\n",
    "| **Log everything** | Params, metrics, and model artifacts to MLflow |\n",
    "| **Evaluate on holdout** | Final metric only from test set (never validation) |\n",
    "| **Save fitted pipeline** | Not just model - entire transformation chain |\n",
    "\n",
    "## Common Mistakes to Avoid\n",
    "\n",
    "| Mistake | Consequence |\n",
    "|---------|-------------|\n",
    "| Fitting scaler on all data | Data leakage - inflated metrics |\n",
    "| Using test set for tuning | Overfitting to test distribution |\n",
    "| No random seed | Non-reproducible results |\n",
    "| Large param grid | Combinatorial explosion, slow training |\n",
    "| Not logging to MLflow | Lost experiments, no comparison |\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- Register best model in MLflow Model Registry\n",
    "- Deploy model for batch or real-time inference\n",
    "- Set up monitoring for model performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
