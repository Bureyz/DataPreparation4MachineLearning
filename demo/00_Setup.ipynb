{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4eb20d",
   "metadata": {},
   "source": [
    "# Setup - Environment Configuration\n",
    "\n",
    "**Objective:** Configure an isolated environment for each training participant.\n",
    "\n",
    "**Scope:**\n",
    "- User detection and unique schema creation\n",
    "- Unity Catalog configuration\n",
    "- Utility functions (environment reset)\n",
    "\n",
    "---\n",
    "\n",
    "## Context and Requirements\n",
    "\n",
    "- **Training day:** All days - required before each Demo notebook\n",
    "- **Notebook type:** Setup (invoked via `%run ./00_Setup`)\n",
    "- **Technical requirements:**\n",
    "  - Databricks Runtime 14.x LTS or newer\n",
    "  - Unity Catalog enabled\n",
    "  - Permissions: CREATE CATALOG, CREATE SCHEMA\n",
    "- **Execution time:** < 1 minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f10e6",
   "metadata": {},
   "source": [
    "## Section 1: User Detection\n",
    "\n",
    "Automatic detection of current user and schema name preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current user email and extract username\n",
    "current_user_email = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "username = current_user_email.split(\"@\")[0].replace(\".\", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "print(f\"Detected user: {current_user_email}\")\n",
    "print(f\"Username for schema: {username}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224ccc68",
   "metadata": {},
   "source": [
    "## Section 2: Catalog and Schema Configuration\n",
    "\n",
    "Definition of target Unity Catalog and unique per-user schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e389b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "catalog_name = \"data_ml_preparation\" # Ensure this catalog exists or use 'hive_metastore' if UC is not enabled\n",
    "schema_name = f\"ml_dp_{username}\"\n",
    "\n",
    "print(f\"Target Catalog: {catalog_name}\")\n",
    "print(f\"Target Schema: {schema_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4990f6f",
   "metadata": {},
   "source": [
    "## Section 3: Environment Creation\n",
    "\n",
    "Create catalog and schema in Unity Catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e27ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Set Schema\n",
    "try:\n",
    "    spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "    spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "    \n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\")\n",
    "    spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "    \n",
    "    print(f\"✅ Successfully configured environment.\")\n",
    "    print(f\"Current context: {catalog_name}.{schema_name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error configuring environment: {e}\")\n",
    "    print(\"Please ensure you have permissions to create catalogs/schemas or contact the instructor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063a4ef",
   "metadata": {},
   "source": [
    "## Section 4: User Context\n",
    "\n",
    "Display current context (for verification):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc22cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display current context for verification\n",
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"CATALOG\", catalog_name),\n",
    "        (\"SCHEMA\", schema_name),\n",
    "        (\"USER\", username),\n",
    "        (\"FULL_PATH\", f\"{catalog_name}.{schema_name}\")\n",
    "    ], [\"Variable\", \"Value\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6571fdc",
   "metadata": {},
   "source": [
    "## Section 5: Utility Functions\n",
    "\n",
    "Function to reset environment (optional - use when you want to start fresh):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b5d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to reset environment (Optional)\n",
    "def reset_environment():\n",
    "    spark.sql(f\"DROP SCHEMA IF EXISTS {schema_name} CASCADE\")\n",
    "    spark.sql(f\"CREATE SCHEMA {schema_name}\")\n",
    "    print(f\"Schema {schema_name} has been reset.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
