{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6613cdc0",
      "metadata": {},
      "source": [
        "# Module 7: Feature Store and MLOps\n",
        "\n",
        "**Training Objective:** Master Databricks Feature Store and Model Registry for production-grade ML workflows.\n",
        "\n",
        "**Scope:**\n",
        "- Feature Store Creation: Creating and populating Feature Tables\n",
        "- Feature Lookup: Creating training datasets with point-in-time correctness\n",
        "- Training & Logging: Training models with feature lineage\n",
        "- Model Registry: Promoting models to Production with Unity Catalog"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d16bd09c",
      "metadata": {},
      "source": [
        "## Context and Requirements\n",
        "\n",
        "- **Training day:** Day 1 - Data Preparation Fundamentals (Advanced)\n",
        "- **Notebook type:** Demo\n",
        "- **Technical requirements:**\n",
        "  - Databricks Runtime 14.x LTS or newer\n",
        "  - Unity Catalog enabled\n",
        "  - Feature Store enabled (default in UC)\n",
        "  - Permissions: CREATE TABLE, SELECT, MODIFY, CREATE MODEL\n",
        "- **Dependencies:** `05_Feature_Engineering.ipynb` (creates `customer_train_engineered` table)\n",
        "- **Execution time:** ~25 minutes\n",
        "\n",
        "> **Note:** Feature Store is essential for production ML - it ensures consistency between training and inference."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fae791db",
      "metadata": {},
      "source": [
        "## Theoretical Introduction\n",
        "\n",
        "**What is Feature Store?**\n",
        "\n",
        "A centralized repository for features that enables:\n",
        "- **Write Once, Use Everywhere**: Define feature logic once, reuse for training and inference\n",
        "- **Training-Serving Consistency**: Same features in development and production\n",
        "- **Point-in-Time Correctness**: Prevent data leakage with temporal joins\n",
        "- **Feature Discovery**: Teams can find and reuse existing features\n",
        "\n",
        "**Feature Store Workflow:**\n",
        "\n",
        "```\n",
        "Raw Data ‚Üí Feature Engineering ‚Üí Feature Table ‚Üí Training Set ‚Üí Model\n",
        "                                       ‚Üì\n",
        "                              Inference (Batch/Online)\n",
        "```\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "| Concept | Description |\n",
        "|---------|-------------|\n",
        "| **Feature Table** | Delta table with primary key and optional timestamp |\n",
        "| **Feature Lookup** | Join features to training labels by key |\n",
        "| **Point-in-Time Join** | Only use features available at observation time |\n",
        "| **fs.log_model** | Model remembers which features it needs |\n",
        "| **score_batch** | Auto-fetches features by ID for inference |\n",
        "\n",
        "**Model Registry with Unity Catalog:**\n",
        "- Models registered in `catalog.schema.model_name`\n",
        "- Use aliases like \"Champion\" and \"Challenger\" for lifecycle management"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8855180",
      "metadata": {},
      "source": [
        "## Per-User Isolation\n",
        "\n",
        "Run the initialization script for per-user catalog and schema isolation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2305051",
      "metadata": {},
      "outputs": [],
      "source": [
        "%run ./00_Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "055d8136",
      "metadata": {},
      "source": [
        "**Initialize Feature Store Client:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e86b40f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from databricks.feature_store import FeatureStoreClient\n",
        "from pyspark.sql.functions import current_timestamp\n",
        "\n",
        "fs = FeatureStoreClient()\n",
        "df = spark.table(\"customer_train_engineered\")\n",
        "\n",
        "# Add timestamp for Feature Store\n",
        "df_fs = df.withColumn(\"event_timestamp\", current_timestamp())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8da36fb",
      "metadata": {},
      "source": [
        "## Section 1: Creating a Feature Table\n",
        "\n",
        "**The Problem:**\n",
        "In traditional ML, data scientists often rewrite feature engineering code for training, and engineers rewrite it again for production. This leads to **Training-Serving Skew** (inconsistencies).\n",
        "\n",
        "**The Solution:**\n",
        "The **Feature Store** acts as a centralized repository.\n",
        "1.  **Write Once:** Define feature logic once.\n",
        "2.  **Use Everywhere:** Fetch features for training (offline) or inference (online) ensuring consistency.\n",
        "3.  **Discovery:** Other teams can find and reuse your features (e.g., \"Customer LTV\").\n",
        "\n",
        "We register our engineered features so others can use them without re-running the engineering code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d160581d",
      "metadata": {},
      "outputs": [],
      "source": [
        "table_name = f\"{catalog_name}.{schema_name}.customer_features\"\n",
        "\n",
        "# Create Feature Table\n",
        "# We use mode=\"overwrite\" to allow re-running this cell\n",
        "fs.create_table(\n",
        "    name=table_name,\n",
        "    primary_keys=[\"id\"], \n",
        "    timestamp_keys=[\"event_timestamp\"],\n",
        "    df=df_fs,\n",
        "    mode=\"overwrite\",\n",
        "    description=\"Customer features: Age, Log Salary, LTV Proxy\"\n",
        ")\n",
        "\n",
        "print(f\"Feature Table {table_name} created.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8e2838",
      "metadata": {},
      "source": [
        "## Section 2: Reading & Training Set (Lookup)\n",
        "\n",
        "One of the main benefits of Feature Store is **Point-in-Time Lookup**.\n",
        "When creating a training set, we need to join features to our labels. Feature Store ensures that for each label (observation), we only use feature values that were available *at that time*, preventing data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df37e09d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Simple Read\n",
        "# We can read the feature table just like any Delta table\n",
        "df_features = fs.read_table(name=table_name)\n",
        "display(df_features.limit(5))\n",
        "\n",
        "# 2. Create Training Set (The \"Lookup\")\n",
        "# We need a \"Spine\" dataframe containing our target variable and keys (IDs)\n",
        "df_spine = spark.table(\"customer_train\").select(\"id\", \"salary\")\n",
        "\n",
        "from databricks.feature_store import FeatureLookup\n",
        "\n",
        "# We define which features we want to fetch from the store\n",
        "feature_lookups = [\n",
        "    FeatureLookup(\n",
        "        table_name=table_name,\n",
        "        feature_names=[\"age_imputed\", \"log_salary\", \"ltv_proxy\"],\n",
        "        lookup_key=\"id\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# fs.create_training_set joins the spine with the features\n",
        "training_set = fs.create_training_set(\n",
        "    df=df_spine,\n",
        "    feature_lookups=feature_lookups,\n",
        "    label=\"salary\",\n",
        "    exclude_columns=[\"id\"] # We don't need ID in the model\n",
        ")\n",
        "\n",
        "# Load into a DataFrame to verify\n",
        "df_training = training_set.load_df()\n",
        "display(df_training.limit(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8f35361",
      "metadata": {},
      "source": [
        "## Section 3: Training & Logging with Feature Store\n",
        "\n",
        "We will now train a model and log it using `fs.log_model`.\n",
        "**Why?**\n",
        "When we log with Feature Store, the model remembers exactly which features it needs. At inference time, we just provide the `id`, and the model automatically fetches the features from the store!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f200dee7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Prepare data for Scikit-Learn\n",
        "pdf = df_training.toPandas()\n",
        "X = pdf.drop(\"salary\", axis=1)\n",
        "y = pdf[\"salary\"]\n",
        "\n",
        "# Train a simple model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Log Model\n",
        "# We use fs.log_model instead of mlflow.sklearn.log_model\n",
        "model_name = f\"{catalog_name}.{schema_name}.customer_salary_model\"\n",
        "\n",
        "with mlflow.start_run(run_name=\"FS_Model_Demo\") as run:\n",
        "    fs.log_model(\n",
        "        model,\n",
        "        artifact_path=\"model\",\n",
        "        flavor=mlflow.sklearn,\n",
        "        training_set=training_set,\n",
        "        registered_model_name=model_name # This registers the model automatically!\n",
        "    )\n",
        "    print(f\"Model logged and registered as: {model_name}\")\n",
        "    print(f\"Run ID: {run.info.run_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccffd1f8",
      "metadata": {},
      "source": [
        "## Section 4: Model Registry (Transition to Production)\n",
        "\n",
        "The model is now registered in Unity Catalog. We can manage its lifecycle using aliases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "926ba59e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "client = MlflowClient()\n",
        "\n",
        "# Get the latest version of the model we just registered\n",
        "latest_version = client.get_registered_model(model_name).latest_versions[0].version\n",
        "\n",
        "print(f\"Latest Version: {latest_version}\")\n",
        "\n",
        "# Transition to Production (Alias in Unity Catalog)\n",
        "# In UC, we use Aliases like 'Champion' or 'Challenger' instead of Stages\n",
        "client.set_registered_model_alias(model_name, \"Champion\", latest_version)\n",
        "\n",
        "print(f\"Model version {latest_version} set as 'Champion'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29e64b81",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate new data (Just IDs!)\n",
        "df_new = spark.createDataFrame([(1,), (2,), (5,)], [\"id\"])\n",
        "\n",
        "print(\"Scoring new data (IDs only)...\")\n",
        "\n",
        "# Score Batch\n",
        "# Note: We use the model URI from Unity Catalog\n",
        "predictions = fs.score_batch(\n",
        "    model_uri=f\"models:/{model_name}/Champion\",\n",
        "    df=df_new\n",
        ")\n",
        "\n",
        "display(predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5627bae",
      "metadata": {},
      "source": [
        "## Best Practices\n",
        "\n",
        "### üéØ Feature Store Strategy Guide:\n",
        "\n",
        "| Aspect | Best Practice | Why |\n",
        "|--------|--------------|-----|\n",
        "| **Primary Keys** | Use stable IDs (customer_id, not row number) | Consistent lookups |\n",
        "| **Timestamps** | Include `event_timestamp` | Point-in-time correctness |\n",
        "| **Feature Names** | Descriptive (e.g., `customer_ltv_30d`) | Discoverability |\n",
        "| **Granularity** | One table per entity type | Cleaner schema |\n",
        "| **Updates** | Use `mode=\"merge\"` for incremental | Efficiency |\n",
        "\n",
        "### ‚ö†Ô∏è Common Mistakes to Avoid:\n",
        "\n",
        "1. **No timestamp column** ‚Üí Cannot do point-in-time joins\n",
        "2. **Duplicating features** ‚Üí Use existing tables, don't recreate\n",
        "3. **Logging without training_set** ‚Üí Model doesn't know its features\n",
        "4. **Using wrong model URI** ‚Üí Include alias (Champion) for production\n",
        "5. **Not testing inference** ‚Üí Always verify score_batch works\n",
        "\n",
        "### üí° Pro Tips:\n",
        "\n",
        "- Use Unity Catalog for governance and lineage\n",
        "- Set up online store for real-time inference (<10ms)\n",
        "- Use aliases (Champion/Challenger) for A/B testing\n",
        "- Monitor feature freshness in production\n",
        "- Document features in the description field"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fe6ae78",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What we achieved:\n",
        "\n",
        "- **Feature Table**: Created centralized feature repository\n",
        "- **Feature Lookup**: Built training set with automatic joins\n",
        "- **fs.log_model**: Logged model with feature lineage\n",
        "- **Model Registry**: Registered and promoted model to Champion\n",
        "- **score_batch**: Demonstrated automatic feature fetching\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "| # | Principle |\n",
        "|---|-----------|\n",
        "| 1 | **Feature Store ensures consistency** - same features everywhere |\n",
        "| 2 | **Point-in-time joins prevent leakage** - use timestamps |\n",
        "| 3 | **fs.log_model links model to features** - automatic inference |\n",
        "| 4 | **Unity Catalog provides governance** - lineage and access control |\n",
        "| 5 | **score_batch simplifies inference** - just provide IDs |\n",
        "\n",
        "### Artifacts Created:\n",
        "\n",
        "| Artifact | Location | Purpose |\n",
        "|----------|----------|---------|\n",
        "| Feature Table | `{catalog}.{schema}.customer_features` | Centralized features |\n",
        "| Registered Model | `{catalog}.{schema}.customer_salary_model` | Production model |\n",
        "| Champion Alias | Applied to latest version | Production deployment |\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "üìö **Next Module:** Module 8 (BONUS) - GenAI, Vector Search & AI Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7aae2ff",
      "metadata": {},
      "source": [
        "## Cleanup\n",
        "\n",
        "Optionally remove demo artifacts created during exercises:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4e810e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleanup - remove demo artifacts created in this notebook\n",
        "\n",
        "# Uncomment the lines below to remove demo artifacts:\n",
        "\n",
        "# spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")  # Feature table\n",
        "# client.delete_registered_model(model_name)  # Registered model\n",
        "\n",
        "# print(\"‚úÖ All demo artifacts removed\")\n",
        "\n",
        "print(\"‚ÑπÔ∏è Cleanup disabled (uncomment code to remove demo artifacts)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18854748",
      "metadata": {},
      "source": [
        "## Section 5: Batch Inference (Scoring)\n",
        "\n",
        "The magic of Feature Store is that we don't need to assemble features manually for inference.\n",
        "We just provide the **IDs**, and `fs.score_batch` automatically looks up the correct features from the store and applies the model."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
