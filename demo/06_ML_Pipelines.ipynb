{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d67373d4-a2c7-4282-a859-635015697ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Module 6: Machine Learning Pipelines\n",
    "\n",
    "## Business Context: TechCorp Salary Prediction Model\n",
    "\n",
    "**The Goal:**\n",
    "TechCorp HR wants to deploy a **Salary Prediction Model** that:\n",
    "1. Suggests fair compensation for new hires based on experience and location\n",
    "2. Identifies underpaid employees for salary adjustments\n",
    "3. Supports budget planning for new positions\n",
    "\n",
    "**What we're building:**\n",
    "A complete ML Pipeline that predicts `salary` based on:\n",
    "- `age` (proxy for experience)\n",
    "- `country` (market rate differences)\n",
    "- `source` (recruitment channel quality)\n",
    "\n",
    "**Why Pipeline?** In production, HR will upload a CSV of candidates. The pipeline must apply the EXACT same transformations (imputation, encoding, scaling) as during training.\n",
    "\n",
    "---\n",
    "\n",
    "**Training Objective:** Master Spark ML Pipelines to create reproducible, production-ready ML workflows with MLflow tracking.\n",
    "\n",
    "**Scope:**\n",
    "- Pipeline Concepts: Why use Pipelines?\n",
    "- Defining Stages: Chaining Imputers, Encoders, Scalers, and Models\n",
    "- MLflow Tracking: Logging experiments, parameters, and metrics\n",
    "- Hyperparameter Tuning: Using CrossValidator for automatic model selection\n",
    "- Model Persistence: Saving the pipeline for production use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bace3dea-02ab-4464-918f-b4ceb8c62ab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Context and Requirements\n",
    "\n",
    "- **Training day:** Day 1 - Data Preparation Fundamentals\n",
    "- **Notebook type:** Demo\n",
    "- **Technical requirements:**\n",
    "  - Databricks Runtime 14.x LTS or newer\n",
    "  - Unity Catalog enabled\n",
    "  - MLflow enabled (default in Databricks)\n",
    "  - Permissions: CREATE TABLE, SELECT, MODIFY\n",
    "- **Dependencies:** `02_Data_Splitting.ipynb` (creates `customer_train`, `customer_test` tables)\n",
    "- **Execution time:** ~30 minutes\n",
    "\n",
    "> **Note:** This module brings together all previous concepts into a production-ready workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2252c80d-e352-48fe-82b7-66ab3a2e2bdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Theoretical Background\n",
    "\n",
    "**Spark ML Pipelines:**\n",
    "A Pipeline is a sequence of stages (Transformers and Estimators) executed in order. This ensures:\n",
    "1. Consistent data transformation between training and inference\n",
    "2. No data leakage (transformers fit only on training data)\n",
    "3. Easy saving/loading of the entire workflow\n",
    "\n",
    "**CrossValidator:**\n",
    "Performs k-fold cross-validation with hyperparameter tuning:\n",
    "- Splits training data into k folds\n",
    "- Trains model on k-1 folds, validates on remaining fold\n",
    "- Repeats for all combinations of hyperparameters\n",
    "- Total models trained: `len(paramGrid) × numFolds`\n",
    "\n",
    "**MLflow with Unity Catalog Models:**\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Model Registry** | `catalog.schema.model_name` format |\n",
    "| **Versioning** | Automatic version tracking (v1, v2, ...) |\n",
    "| **Aliases** | `@champion`, `@challenger` for deployment stages |\n",
    "| **Governance** | Unity Catalog permissions apply |\n",
    "| **Lineage** | Track data and model dependencies |\n",
    "\n",
    "**️ Unity Catalog requires Model Signature:**\n",
    "\n",
    "Unity Catalog models **MUST** include a signature (input/output schema). Without it, registration fails.\n",
    "\n",
    "```python\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Infer signature from training data and predictions\n",
    "signature = infer_signature(train_df.toPandas(), predictions.select(\"prediction\").toPandas())\n",
    "\n",
    "# Register with signature\n",
    "mlflow.spark.log_model(\n",
    "    model, \n",
    "    \"model\", \n",
    "    signature=signature,\n",
    "    input_example=train_df.limit(5).toPandas(),\n",
    "    registered_model_name=\"catalog.schema.model\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12754d2a-cd81-4bfe-a09a-08ff7ea79b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Per-User Isolation\n",
    "\n",
    "Run the initialization script for per-user catalog and schema isolation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c617ec0d-8cda-43b6-92a4-48be267e0eab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Preprocessing Methods by Model Type\n",
    "\n",
    "Different ML models have different requirements for data preprocessing. Choosing the wrong method can hurt performance!\n",
    "\n",
    "### Scaling Requirements\n",
    "\n",
    "| Model Type | Scaling Required? | Recommended Scaler | Why? |\n",
    "|------------|-------------------|-------------------|------|\n",
    "| **Linear Regression** | Yes | StandardScaler / RobustScaler | Coefficients sensitive to feature magnitude |\n",
    "| **Logistic Regression** | Yes | StandardScaler | Gradient descent converges faster |\n",
    "| **SVM** | Yes | StandardScaler | Distance-based, needs normalized features |\n",
    "| **k-NN** | Yes | MinMaxScaler / StandardScaler | Distance-based algorithm |\n",
    "| **Neural Networks** | Yes | StandardScaler / MinMaxScaler | Activation functions work best in [-1,1] or [0,1] |\n",
    "| **Decision Tree** | No | None | Splits based on thresholds, scale-invariant |\n",
    "| **Random Forest** | No | None | Ensemble of trees, scale-invariant |\n",
    "| **Gradient Boosting (XGBoost, LightGBM)** | No | None | Tree-based, scale-invariant |\n",
    "| **Naive Bayes** | No | None | Probability-based, not affected by scale |\n",
    "\n",
    "### Encoding Categorical Variables\n",
    "\n",
    "| Encoding Method | When to Use | Models | Spark MLlib Class |\n",
    "|----------------|-------------|--------|-------------------|\n",
    "| **Label Encoding** (0, 1, 2...) | Ordinal categories (Low/Medium/High) | Tree-based models | `StringIndexer` |\n",
    "| **One-Hot Encoding** | Nominal categories (Country, Color) | Linear models, NN | `OneHotEncoder` |\n",
    "| **Target Encoding** | High cardinality (1000+ categories) | All models | Custom / Feature Store |\n",
    "| **Binary Encoding** | Medium cardinality (10-100 categories) | All models | Custom |\n",
    "\n",
    "### Common Mistakes\n",
    "\n",
    "| Mistake | Problem | Solution |\n",
    "|---------|---------|----------|\n",
    "| OneHot + Tree models | Unnecessary, creates sparse features | Use `StringIndexer` only |\n",
    "| Scaling OneHot features | Destroys 0/1 meaning | Scale only numeric features |\n",
    "| Label encoding for Linear models | Implies false ordering (France=1 < Germany=2) | Use OneHot instead |\n",
    "| Scaling before Split | Data leakage from test set | Always fit scaler on train only |\n",
    "\n",
    "### Quick Reference: Pipeline by Model\n",
    "\n",
    "**For Linear/Logistic Regression:**\n",
    "```\n",
    "Imputer -> StringIndexer -> OneHotEncoder -> VectorAssembler(numeric) -> Scaler -> VectorAssembler(all) -> Model\n",
    "```\n",
    "\n",
    "**For Tree-based Models (RF, GBT, XGBoost):**\n",
    "```\n",
    "Imputer -> StringIndexer -> VectorAssembler -> Model\n",
    "```\n",
    "*No scaling, no OneHot needed!*\n",
    "\n",
    "**For Neural Networks:**\n",
    "```\n",
    "Imputer -> StringIndexer -> OneHotEncoder -> VectorAssembler -> StandardScaler -> Model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3189da62-9293-44b8-b06f-e52717ca05cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29214168-8795-4f82-b507-8c9da48ddb8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Import Libraries and Load Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f82d870-ef82-4b9e-896c-e6d5f93d1271",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Imputer, StringIndexer, OneHotEncoder, VectorAssembler, RobustScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Load Raw Split Data (We start from scratch in the pipeline!)\n",
    "train_df = spark.table(\"customer_train\")\n",
    "test_df = spark.table(\"customer_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "648d065a-0304-4d69-98de-132cd9b82b9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 1: Defining Pipeline Stages\n",
    "\n",
    "**Why use a Pipeline?**\n",
    "1.  **Prevention of Data Leakage:** When we calculate things like \"Mean\" for imputation or \"Max\" for scaling, we must calculate them **only on the Training set** and apply them to the Test set. A Pipeline ensures `fit()` is called on Train and `transform()` on Test.\n",
    "2.  **Reproducibility:** It bundles all preprocessing steps and the model into a single artifact.\n",
    "3.  **Simplicity:** You can save/load the entire workflow as one object.\n",
    "\n",
    "We will reconstruct our manual steps into a reusable Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bd05ecf-f246-4863-964e-bbc5652f8f5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Transformation and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dafc4f7b-8ad3-4ce7-9363-ccf05f3fa27b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, upper, datediff, current_date, col, when, coalesce, lit\n",
    "\n",
    "# IMPORTANT: Apply same transformations to BOTH train and test data!\n",
    "\n",
    "# 1. Basic cleaning\n",
    "train_df = train_df.dropDuplicates()\n",
    "train_df = train_df.withColumn(\"country\", regexp_replace(upper(\"country\"), r\"\\\\\", \"\"))\n",
    "\n",
    "test_df = test_df.dropDuplicates()\n",
    "test_df = test_df.withColumn(\"country\", regexp_replace(upper(\"country\"), r\"\\\\\", \"\"))\n",
    "\n",
    "# 2. Feature Engineering (matching Module 05)\n",
    "# Calculate tenure_days from registration_date\n",
    "train_df = train_df.withColumn(\"tenure_days\", datediff(current_date(), col(\"registration_date\")))\n",
    "test_df = test_df.withColumn(\"tenure_days\", datediff(current_date(), col(\"registration_date\")))\n",
    "\n",
    "# Fill missing source with \"UNKNOWN\"\n",
    "train_df = train_df.withColumn(\"source\", coalesce(col(\"source\"), lit(\"UNKNOWN\")))\n",
    "test_df = test_df.withColumn(\"source\", coalesce(col(\"source\"), lit(\"UNKNOWN\")))\n",
    "\n",
    "# Show available features\n",
    "print(\"Available columns for modeling:\")\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ea172ad-e096-4ddf-bc30-b2f1527bce32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a64e5782-9d90-4702-a96e-f338330a781b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PIPELINE - SALARY PREDICTION MODEL\n",
    "# ============================================\n",
    "# Target: salary_imputed\n",
    "# Features for predicting salary:\n",
    "#   - age_imputed: base age\n",
    "#   - experience_years: age - 22 (years since graduation)\n",
    "#   - tenure_days: time with company\n",
    "#   - ltv_proxy: age * tenure (interaction)\n",
    "#   - country, source: categorical features\n",
    "\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "# 1. Imputation (age, salary, tenure_days)\n",
    "imputer = Imputer(\n",
    "    inputCols=[\"age\", \"salary\", \"tenure_days\"], \n",
    "    outputCols=[\"age_imputed\", \"salary_imputed\", \"tenure_days_imputed\"]\n",
    ").setStrategy(\"median\")\n",
    "\n",
    "# 2. Feature Engineering\n",
    "# Create experience_years (key predictor!) and ltv_proxy\n",
    "feature_engineer = SQLTransformer(\n",
    "    statement=\"\"\"\n",
    "    SELECT *, \n",
    "           age_imputed - 22 AS experience_years,\n",
    "           age_imputed * tenure_days_imputed AS ltv_proxy,\n",
    "           AVG(salary_imputed) OVER (PARTITION BY country ORDER BY tenure_days_imputed \n",
    "                                     ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS country_salary_avg_rolling,\n",
    "           CASE \n",
    "               WHEN salary_imputed > country_salary_avg_rolling * 1.03 THEN 1\n",
    "               WHEN salary_imputed < country_salary_avg_rolling * 0.97 THEN -1\n",
    "               ELSE 0\n",
    "           END AS salary_3pct_flag\n",
    "    FROM __THIS__\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 3. Encoding (country and source)\n",
    "indexer_country = StringIndexer(inputCol=\"country\", outputCol=\"country_idx\", handleInvalid=\"keep\")\n",
    "indexer_source = StringIndexer(inputCol=\"source\", outputCol=\"source_idx\", handleInvalid=\"keep\")\n",
    "encoder = OneHotEncoder(inputCols=[\"country_idx\", \"source_idx\"], outputCols=[\"country_vec\", \"source_vec\"])\n",
    "\n",
    "# 4. Assembly - Features for salary prediction\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"age_imputed\",         # Base age\n",
    "        \"experience_years\",    # Years since graduation (key predictor!)\n",
    "        \"tenure_days_imputed\",\n",
    "        \"salary_3pct_flag\",    # Time with company  \n",
    "        \"ltv_proxy\",           # Age * Tenure interaction\n",
    "        \"country_vec\",         # Country one-hot encoded\n",
    "        \"source_vec\"           # Source one-hot encoded\n",
    "    ], \n",
    "    outputCol=\"features_raw\", \n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# 5. Scaling\n",
    "scaler = RobustScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
    "\n",
    "# 6. Model\n",
    "lr = LinearRegression(labelCol=\"salary_imputed\", featuresCol=\"features\")\n",
    "\n",
    "# --- The Pipeline ---\n",
    "pipeline = Pipeline(stages=[\n",
    "    imputer, \n",
    "    feature_engineer,\n",
    "    indexer_country, \n",
    "    indexer_source, \n",
    "    encoder, \n",
    "    assembler, \n",
    "    scaler, \n",
    "    lr\n",
    "])\n",
    "\n",
    "print(\"Salary Prediction Pipeline created with features:\")\n",
    "print(\"  - age_imputed\")\n",
    "print(\"  - experience_years (age - 22)\")\n",
    "print(\"  - tenure_days_imputed\")\n",
    "print(\"  - ltv_proxy (age * tenure_days)\")\n",
    "print(\"  - country_vec (one-hot)\")\n",
    "print(\"  - source_vec (one-hot)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9df7852-1fd1-4bf3-a704-2eab241c94ce",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764858805890}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a pipeline WITHOUT the model (without LinearRegression)\n",
    "# stages[:-1] means \"all steps from the beginning, but exclude the last one\"\n",
    "preprocessing_pipeline = Pipeline(stages=pipeline.getStages()[:-1])\n",
    "\n",
    "# Now this is just a Transformer, so it works immediately!\n",
    "# You don't need to do fit() (unless you have Imputer/Scalers, then fit is fast)\n",
    "processed_data = preprocessing_pipeline.fit(train_df).transform(train_df)\n",
    "\n",
    "# Preview what goes into the model\n",
    "display(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3599b4c-f1e5-48e3-be4e-3b89024a4831",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 2: Training with MLflow\n",
    "\n",
    "We use `mlflow.start_run()` to track this experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94a06500-9a9a-40b8-98ba-ffbdd2bfd4c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### What is a Model Signature?\n",
    "\n",
    "**model signature** defines the schema (column names and data types) of the inputs and outputs that a machine learning model expects and produces. In MLflow and Databricks, model signatures:\n",
    "\n",
    "- Act as a contract for how to interact with the model.\n",
    "- Enable automatic validation of input/output data formats.\n",
    "- Are required for registering models in Unity Catalog.\n",
    "- Help document and enforce correct usage during deployment.\n",
    "\n",
    "**Example:**  \n",
    "A model that predicts salary might have this signature:\n",
    "- **Inputs:** `age` (integer), `country` (string), `source` (string)\n",
    "- **Output:** `salary` (double)\n",
    "\n",
    "Model signatures ensure consistency, safety, and reproducibility in production ML workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d2819fd-4180-4022-b717-f48258c2c919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set MLflow to use Unity Catalog for model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Import signature inference for Unity Catalog (REQUIRED!)\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Set Experiment\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "experiment_path = f\"/Users/{username}/dp4ml_pipeline_demo\"\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "# Model name for Unity Catalog\n",
    "model_name = f\"{catalog_name}.{schema_name}.salary_prediction_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5304c88-a958-4dd0-917a-3d4b770ded1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**RegressionEvaluator** is a PySpark class used to evaluate regression models. It computes metrics like RMSE, MAE, and R² by comparing the model's predictions to the true labels.\n",
    "\n",
    "**evaluate** is a method of RegressionEvaluator that calculates the chosen metric on a given DataFrame containing prediction and label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98a8ee38-b17f-48a2-853a-97cf5ff1ef25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"salary_prediction_v1\"):\n",
    "    \n",
    "    # Log Parameters\n",
    "    mlflow.log_param(\"model\", \"LinearRegression\")\n",
    "    mlflow.log_param(\"scaler\", \"RobustScaler\")\n",
    "    \n",
    "    # Fit Pipeline\n",
    "    print(\"Training Pipeline...\")\n",
    "    model = pipeline.fit(train_df)\n",
    "    \n",
    "    # Evaluate\n",
    "    predictions = model.transform(test_df)\n",
    "    evaluator = RegressionEvaluator(labelCol=\"salary_imputed\", metricName=\"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    \n",
    "    # Log Metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    # Infer model signature from input and output data\n",
    "    # Unity Catalog REQUIRES signature for model registration\n",
    "    input_example = train_df.limit(5).toPandas()\n",
    "    signature = infer_signature(\n",
    "        train_df.toPandas(),\n",
    "        predictions.select(\"prediction\").toPandas()\n",
    "    )\n",
    "    \n",
    "    evaluator_r2 = RegressionEvaluator(labelCol=\"salary_imputed\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "    r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "    # Log Metrics\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Log Model and Register to Unity Catalog with signature\n",
    "    mlflow.spark.log_model(\n",
    "        model, \n",
    "        \"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=model_name  # Auto-register to UC\n",
    "    )\n",
    "    \n",
    "    print(f\"Model registered to Unity Catalog: {model_name}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ba3ca0-de51-4a6e-a087-af4ec75d47a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Section 3: Hyperparameter Tuning with CrossValidator\n",
    "\n",
    "**Why tune hyperparameters?**\n",
    "In the previous example, we used default settings for `LinearRegression`. But models have \"knobs\" (hyperparameters) that can drastically change performance (e.g., `regParam` for regularization).\n",
    "\n",
    "**CrossValidator** automates this:\n",
    "1.  Define a **ParamGrid** (list of hyperparameters to try).\n",
    "2.  CrossValidator trains $k$ models for each combination (k-fold).\n",
    "3.  It picks the best model based on the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c8f3ca6-3733-4b5a-9ec7-052f1342fce5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# We reuse our ENHANCED pipeline with feature engineering\n",
    "lr_tune = LinearRegression(labelCol=\"salary_imputed\", featuresCol=\"features\")\n",
    "\n",
    "# Use the same enhanced pipeline with all features\n",
    "pipeline_tune = Pipeline(stages=[\n",
    "    imputer, \n",
    "    feature_engineer,      # Feature engineering step\n",
    "    indexer_country, \n",
    "    indexer_source, \n",
    "    encoder, \n",
    "    assembler, \n",
    "    scaler, \n",
    "    lr_tune\n",
    "])\n",
    "\n",
    "# Define the Parameter Grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr_tune.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .addGrid(lr_tune.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "print(f\"Number of hyperparameter combinations to test: {len(paramGrid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cef2839f-3c22-4550-92e1-eca1deccc9fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create CrossValidator\n",
    "# numFolds=3 means we do 3-fold cross-validation for each param combo\n",
    "# Total fits = len(paramGrid) * numFolds = 9 * 3 = 27 models!\n",
    "\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline_tune,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=RegressionEvaluator(labelCol=\"salary_imputed\", metricName=\"r2\"),\n",
    "    numFolds=3,\n",
    "    parallelism=4,  # Train 4 models in parallel (faster on clusters)\n",
    "    seed=42  # Added seed for reproducibility\n",
    ")\n",
    "\n",
    "print(\"CrossValidator configured. Training will evaluate 27 models...\")\n",
    "\n",
    "# Fit CrossValidator (This takes longer!)\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# Get best model\n",
    "best_model = cv_model.bestModel\n",
    "print(\"Best model found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21470dcc-4ea3-4295-8b4f-2d6c82b41a97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3688a08-061f-40d8-8454-6d2ba1b74153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Explanation of the Code:**\n",
    "\n",
    "- **Evaluate the best model on TEST set:**  \n",
    "  We use the trained pipeline (`best_model`) to generate predictions on the test dataset (`test_df`). The `evaluator` (typically a RegressionEvaluator) computes the Root Mean Squared Error (RMSE) on these predictions, giving us a measure of model accuracy on unseen data.\n",
    "\n",
    "- **Extract the best hyperparameters from the LinearRegression stage:**  \n",
    "  The pipeline's last stage is the fitted `LinearRegressionModel`. We access it via `best_model.stages[-1]` to inspect which hyperparameters (like `regParam`, `elasticNetParam`) were chosen as best during cross-validation.\n",
    "\n",
    "- **Compute R2 on test set:**  \n",
    "  We create a new `RegressionEvaluator` set to the R2 metric, then evaluate the predictions to see how much variance in salary is explained by the model (R2 score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "854be9d2-2761-4a90-b88d-f691a06abe60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Evaluate the best model on TEST set\n",
    "predictions_cv = best_model.transform(test_df)\n",
    "evaluator = RegressionEvaluator(labelCol=\"salary_imputed\", metricName=\"rmse\")\n",
    "rmse_cv = evaluator.evaluate(predictions_cv)\n",
    "\n",
    "# Extract the best hyperparameters from the LinearRegression stage\n",
    "# The last stage in the pipeline is the LinearRegressionModel\n",
    "lr_model_stage = best_model.stages[-1]\n",
    "\n",
    "# Compute R2 on test set\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"salary_imputed\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2_cv = evaluator_r2.evaluate(predictions_cv)\n",
    "\n",
    "# Compute MAE for additional insight\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"salary_imputed\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae_cv = evaluator_mae.evaluate(predictions_cv)\n",
    "\n",
    "print(f\"Best Model RMSE: {rmse_cv:.4f}\")\n",
    "print(f\"Best Model R2: {r2_cv:.4f}\")\n",
    "print(f\"Best Model MAE: {mae_cv:.4f}\")\n",
    "print(f\"Best regParam: {lr_model_stage.getRegParam()}\")\n",
    "print(f\"Best elasticNetParam: {lr_model_stage.getElasticNetParam()}\")\n",
    "\n",
    "# Show cross-validation average metrics for all parameter combinations\n",
    "print(\"\\n--- Cross-Validation Results (avg RMSE for each param combo) ---\")\n",
    "avg_metrics = cv_model.avgMetrics\n",
    "for i, (params, metric) in enumerate(zip(paramGrid, avg_metrics)):\n",
    "    reg = params[lr_tune.regParam]\n",
    "    elastic = params[lr_tune.elasticNetParam]\n",
    "    print(f\"  regParam={reg}, elasticNetParam={elastic} -> avg RMSE: {metric:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00affcf9-bca0-495e-addf-d1ef1ce99cdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "These lines print the evaluation metrics and hyperparameters of the best model found by cross-validation:\n",
    "\n",
    "- **Best Model RMSE: `{rmse_cv}`**  \n",
    "  Shows the Root Mean Squared Error (RMSE) of the best model on the test set. Lower RMSE means better predictive accuracy.\n",
    "\n",
    "- **Best Model R2: `{r2_cv}`**  \n",
    "  Shows the R-squared (coefficient of determination) of the best model on the test set. Higher R2 (closer to 1) means the model explains more variance in the target variable.\n",
    "\n",
    "- **Best regParam: `{lr_model_stage.getRegParam()}`**  \n",
    "  Displays the value of the regularization parameter (regParam) chosen by cross-validation. This controls the amount of regularization applied to the model to prevent overfitting.\n",
    "\n",
    "- **Best elasticNetParam: `{lr_model_stage.getElasticNetParam()}`**  \n",
    "  Displays the value of the elasticNet mixing parameter (elasticNetParam) chosen by cross-validation. This controls the mix between L1 (lasso) and L2 (ridge) regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e92c9920-ec89-4c98-9769-fa3d20efd5f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "model_name = f\"{catalog_name}.{schema_name}.salary_prediction_best_model_tuned\"\n",
    "\n",
    "# Infer signature from train and test data\n",
    "input_example = train_df.limit(5).toPandas()\n",
    "signature = infer_signature(\n",
    "    train_df.toPandas(),\n",
    "    best_model.transform(test_df).select(\"prediction\").toPandas()\n",
    ")\n",
    "\n",
    "# Register the best model to Unity Catalog\n",
    "mlflow.spark.log_model(\n",
    "    best_model,\n",
    "    \"best_model\",\n",
    "    signature=signature,\n",
    "    input_example=input_example,\n",
    "    registered_model_name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c2cfcf8-b12f-4763-bee1-29eb9d1b750a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Best Practices\n",
    "\n",
    "### Pipeline Strategy Guide:\n",
    "\n",
    "| Component | Best Practice | Why |\n",
    "|-----------|--------------|-----|\n",
    "| **Order of stages** | Impute → Encode → Scale → Model | Data dependencies |\n",
    "| **handleInvalid** | Use \"keep\" for StringIndexer | Handle new categories |\n",
    "| **Scaler choice** | RobustScaler for outliers | Most robust default |\n",
    "| **CrossValidator folds** | 3-5 for large data, 5-10 for small | Balance bias/variance |\n",
    "| **MLflow logging** | Log params, metrics, AND model | Full reproducibility |\n",
    "\n",
    "### Common Mistakes to Avoid:\n",
    "\n",
    "1. **Fitting pipeline on all data** → Data leakage\n",
    "2. **Too many CV folds** → Slow training, no benefit\n",
    "3. **Not logging to MLflow** → Lost experiments\n",
    "4. **Huge param grids** → Combinatorial explosion\n",
    "5. **Not saving the best model** → Can't reproduce\n",
    "\n",
    "### Pro Tips:\n",
    "\n",
    "- Use `parallelism` parameter in CrossValidator for faster training\n",
    "- Start with small param grid, expand based on results\n",
    "- Always evaluate on holdout TEST set (not validation)\n",
    "- Use MLflow Model Registry for production deployment\n",
    "- Save both the pipeline AND the fitted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7ec5583-7def-4b0c-9ea3-17899891f8ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "### What we achieved:\n",
    "\n",
    "- **Pipeline Definition**: Created end-to-end workflow (Impute → Encode → Scale → Model)\n",
    "- **MLflow Tracking**: Logged parameters, metrics, and model artifacts\n",
    "- **Unity Catalog Models**: Registered model with governance and versioning\n",
    "- **CrossValidator**: Automated hyperparameter search with 3-fold CV\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "| # | Principle |\n",
    "|---|-----------|\n",
    "| 1 | **Pipelines prevent data leakage** - fit on train, transform on test |\n",
    "| 2 | **MLflow is essential** - track all experiments |\n",
    "| 3 | **Unity Catalog Models** - governance, versioning, lineage |\n",
    "| 4 | **CrossValidator automates tuning** - finds best hyperparameters |\n",
    "| 5 | **Evaluate on TEST only once** - final unbiased estimate |\n",
    "\n",
    "### Unity Catalog Artifacts Created:\n",
    "\n",
    "| Artifact | Location | Purpose |\n",
    "|----------|----------|---------|\n",
    "| Experiment | `/Users/{user}/dp4ml_pipeline_demo` | Group runs |\n",
    "| Model | `{catalog}.{schema}.salary_prediction_model` | Production deployment |\n",
    "| Versions | v1, v2, ... | Track model iterations |\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "**Next Module:** Module 7 - Feature Store & MLflow (production ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f57225-7c95-4201-afe0-dc1ccd71a69e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "Optionally remove demo artifacts created during exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2502c8fb-9ca4-4fdc-b23f-c95c432de57d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cleanup - remove demo artifacts created in this notebook\n",
    "\n",
    "# Uncomment the lines below to remove demo artifacts:\n",
    "\n",
    "# import shutil\n",
    "# shutil.rmtree(model_path, ignore_errors=True)\n",
    "# mlflow.delete_experiment(mlflow.get_experiment_by_name(experiment_path).experiment_id)\n",
    "\n",
    "# print(\"All demo artifacts removed\")\n",
    "\n",
    "print(\"Cleanup disabled (uncomment code to remove demo artifacts)\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_ML_Pipelines",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
