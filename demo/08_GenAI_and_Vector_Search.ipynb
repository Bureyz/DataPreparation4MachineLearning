{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb1f5e6",
   "metadata": {},
   "source": [
    "# Module 8 (BONUS): GenAI, Vector Search & AI Functions\n",
    "\n",
    "**Description:**\n",
    "This is a **BONUS** module that goes beyond traditional Data Preparation.\n",
    "Databricks is not just for traditional ML. It now integrates Generative AI deeply into the platform. This module explores the \"New\" AI capabilities: using LLMs directly in SQL and building Vector Search indexes for RAG (Retrieval Augmented Generation) applications.\n",
    "\n",
    "**Agenda:**\n",
    "1.  **AI Functions:** Using built-in SQL functions (`ai_analyze_sentiment`, `ai_query`) to process text with LLMs.\n",
    "2.  **Embeddings & Vector Search:** Understanding how text is converted to vectors and searching by semantic similarity.\n",
    "3.  **RAG Concept:** A brief look at how Vector Search powers Chatbots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397868d",
   "metadata": {},
   "source": [
    "## Context and Requirements\n",
    "\n",
    "| Attribute | Value |\n",
    "|-----------|-------|\n",
    "| **Training Day** | Day 2 |\n",
    "| **Module Type** | BONUS - Demo Notebook |\n",
    "| **Technical Requirements** | Databricks Runtime ML 14.3 LTS or newer |\n",
    "| **Dependencies** | Unity Catalog, Model Serving endpoints (optional) |\n",
    "| **Estimated Time** | 30-45 minutes |\n",
    "\n",
    "**Important Compatibility Notes:**\n",
    "- This notebook requires **Databricks Runtime 14.3 LTS or newer**\n",
    "- AI Functions (`ai_analyze_sentiment`, `ai_query`) require **Serverless SQL** or compatible runtime\n",
    "- Vector Search requires a provisioned **Vector Search Endpoint**\n",
    "- Some features may not work on older runtimes or community edition\n",
    "\n",
    "**Note:** This is a BONUS module introducing GenAI concepts. The notebook is designed to demonstrate concepts even without full infrastructure - code that requires specific endpoints is commented out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2135c69d",
   "metadata": {},
   "source": [
    "## Theoretical Introduction\n",
    "\n",
    "### GenAI Ecosystem in Databricks\n",
    "\n",
    "| Component | Description | Use Case |\n",
    "|-----------|-------------|----------|\n",
    "| **AI Functions** | SQL functions powered by LLMs | Text analysis, sentiment, extraction |\n",
    "| **Embeddings** | Vector representations of text | Semantic similarity, search |\n",
    "| **Vector Search** | Index and query vector embeddings | RAG, recommendation systems |\n",
    "| **Model Serving** | Deploy and serve ML/LLM models | Real-time inference |\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Embeddings:**\n",
    "- Dense vector representations of text (typically 768-4096 dimensions)\n",
    "- Similar meanings → similar vectors (cosine similarity)\n",
    "- Foundation for semantic search and RAG\n",
    "\n",
    "**Vector Search:**\n",
    "- Efficient nearest neighbor search in high-dimensional space\n",
    "- Enables \"find similar documents\" at scale\n",
    "- Databricks offers managed Vector Search with Delta Sync\n",
    "\n",
    "**RAG (Retrieval-Augmented Generation):**\n",
    "- Combine LLM reasoning with private knowledge\n",
    "- Steps: Query → Retrieve relevant docs → Generate answer with context\n",
    "- Reduces hallucinations and enables company-specific AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c821fee",
   "metadata": {},
   "source": [
    "## Per-User Isolation\n",
    "\n",
    "Run the setup notebook to configure your isolated environment with unique catalog and schema names. This ensures your GenAI experiments don't interfere with other participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Setup\n",
    "# Option 1: Run setup notebook (works in Databricks)\n",
    "# %run ./00_Setup\n",
    "\n",
    "# Option 2: Manual setup (fallback for compatibility)\n",
    "try:\n",
    "    # Try to get variables from 00_Setup if already run\n",
    "    print(f\"Using catalog: {catalog_name}, schema: {schema_name}\")\n",
    "except NameError:\n",
    "    # Fallback: Define variables manually\n",
    "    username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "    user_prefix = username.split(\"@\")[0].replace(\".\", \"_\").replace(\"-\", \"_\")[:20]\n",
    "    catalog_name = \"hive_metastore\"  # Or your Unity Catalog name\n",
    "    schema_name = f\"dp4ml_{user_prefix}\"\n",
    "    \n",
    "    # Create schema if not exists\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "    spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "    spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "    \n",
    "    print(f\"Manual setup complete:\")\n",
    "    print(f\"  Catalog: {catalog_name}\")\n",
    "    print(f\"  Schema: {schema_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c0ed12",
   "metadata": {},
   "source": [
    "## Section 1: AI Functions in SQL\n",
    "\n",
    "Databricks now allows you to call Large Language Models (LLMs) directly from SQL. This democratizes AI, allowing Data Analysts to perform complex text tasks without Python.\n",
    "\n",
    "**Available Functions:**\n",
    "- `ai_analyze_sentiment(text)`: Returns 'positive', 'negative', 'neutral'.\n",
    "- `ai_classify(text, categories)`: Classifies text into provided labels.\n",
    "- `ai_summarize(text)`: Summarizes long text.\n",
    "- `ai_translate(text, lang)`: Translates text.\n",
    "- `ai_query(model, prompt)`: Sends a custom prompt to a served model (e.g., Llama 3, DBRX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a468df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data - customer reviews or support tickets\n",
    "reviews_data = [\n",
    "    (1, \"I absolutely love this product! Fast shipping and great quality.\"),\n",
    "    (2, \"The item arrived damaged and the support team was rude.\"),\n",
    "    (3, \"It's okay, does the job but nothing special.\"),\n",
    "    (4, \"Can you help me reset my password?\"),\n",
    "    (5, \"Where is my refund for order #12345?\")\n",
    "]\n",
    "\n",
    "df_reviews = spark.createDataFrame(reviews_data, [\"id\", \"text\"])\n",
    "\n",
    "# Save to table\n",
    "try:\n",
    "    df_reviews.write.mode(\"overwrite\").saveAsTable(f\"{catalog_name}.{schema_name}.customer_reviews\")\n",
    "    print(f\"Table created: {catalog_name}.{schema_name}.customer_reviews\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save table: {e}\")\n",
    "    print(\"Continuing with DataFrame in memory...\")\n",
    "\n",
    "display(df_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f81035",
   "metadata": {},
   "source": [
    "### Example 1.1: Sentiment Analysis & Classification\n",
    "We can use `ai_analyze_sentiment` to quickly gauge customer satisfaction and `ai_classify` to route tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c67d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Functions - Sentiment Analysis & Classification\n",
    "# NOTE: These functions require Databricks Runtime 14.3+ with AI Functions enabled\n",
    "# They may not work on all workspace configurations\n",
    "\n",
    "try:\n",
    "    df_ai = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        text,\n",
    "        ai_analyze_sentiment(text) as sentiment,\n",
    "        ai_classify(text, ARRAY('complaint', 'praise', 'support_request', 'billing')) as category\n",
    "    FROM {catalog_name}.{schema_name}.customer_reviews\n",
    "    \"\"\")\n",
    "    display(df_ai)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"AI Functions not available: {e}\")\n",
    "    print(\"\\nThis feature requires:\")\n",
    "    print(\"  - Databricks Runtime 14.3 LTS or newer\")\n",
    "    print(\"  - Serverless SQL or AI Functions enabled workspace\")\n",
    "    print(\"  - Unity Catalog enabled\")\n",
    "    print(\"\\nManual alternative: Use Python libraries like transformers or openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574acd3",
   "metadata": {},
   "source": [
    "### Example 1.2: Generative AI with `ai_query`\n",
    "For more complex tasks, we can ask an LLM (like Llama 3 or DBRX) to generate text.\n",
    "*Note: This requires a Model Serving Endpoint to be active.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870de48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generating a polite response to the customer\n",
    "# We wrap this in a try-catch block or comment it out because it requires a paid Model Serving endpoint.\n",
    "\n",
    "\"\"\"\n",
    "query = f'''\n",
    "SELECT \n",
    "    id,\n",
    "    text,\n",
    "    ai_query(\n",
    "        'databricks-meta-llama-3-70b-instruct',\n",
    "        CONCAT('Write a short, polite response to this customer review: ', text)\n",
    "    ) as suggested_response\n",
    "FROM {catalog_name}.{schema_name}.customer_reviews\n",
    "'''\n",
    "# display(spark.sql(query))\n",
    "\"\"\"\n",
    "print(\"To run ai_query, uncomment the code above and ensure you have a Model Serving endpoint (e.g., Llama 3) active.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527c998",
   "metadata": {},
   "source": [
    "## Section 2: Embeddings & Vector Search\n",
    "\n",
    "**What is an Embedding?**\n",
    "Computers don't understand text; they understand numbers. An **Embedding** is a way to convert text into a long list of numbers (a vector), e.g., `[0.12, -0.5, 0.88, ...]`.\n",
    "- **Magic Property:** Texts with similar *meanings* will have vectors that are mathematically *close* to each other.\n",
    "- \"King\" and \"Queen\" will be close. \"Apple\" and \"Car\" will be far apart.\n",
    "\n",
    "**What is Vector Search?**\n",
    "It's a specialized database that indexes these vectors to perform \"Nearest Neighbor\" search extremely fast. This is the foundation of **RAG (Retrieval Augmented Generation)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5056ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Source Data (Knowledge Base)\n",
    "# Sample product documentation for Vector Search demo\n",
    "docs_data = [\n",
    "    (1, \"Electric Forklift 2000: Ideal for indoor warehouse use. Zero emissions. 2-ton capacity.\"),\n",
    "    (2, \"Diesel Titan X: Heavy-duty outdoor forklift. 5-ton capacity. Best for rough terrain.\"),\n",
    "    (3, \"Hand Pallet Jack: Manual tool for moving light pallets up to 500kg.\"),\n",
    "    (4, \"Warehouse Automation Suite: Software for inventory management and robot control.\")\n",
    "]\n",
    "\n",
    "df_docs = spark.createDataFrame(docs_data, [\"id\", \"content\"])\n",
    "\n",
    "# Save with Change Data Feed enabled (required for Vector Search sync)\n",
    "try:\n",
    "    df_docs.write.format(\"delta\") \\\n",
    "        .option(\"delta.enableChangeDataFeed\", \"true\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .saveAsTable(f\"{catalog_name}.{schema_name}.product_docs\")\n",
    "    print(f\"✅ Knowledge Base created: {catalog_name}.{schema_name}.product_docs\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not save with Delta format: {e}\")\n",
    "    print(\"Trying without Change Data Feed...\")\n",
    "    try:\n",
    "        df_docs.write.mode(\"overwrite\").saveAsTable(f\"{catalog_name}.{schema_name}.product_docs\")\n",
    "        print(\"✅ Table created (without CDF)\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Could not create table: {e2}\")\n",
    "        print(\"Continuing with DataFrame in memory...\")\n",
    "\n",
    "display(df_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074c05ec",
   "metadata": {},
   "source": [
    "### Example 2.1: Creating a Vector Index\n",
    "\n",
    "To make this searchable, we would create a **Vector Search Index**.\n",
    "Databricks manages the embedding process for us (Source Table -> Embedding Model -> Vector Index).\n",
    "\n",
    "*Note: The code below requires a Vector Search Endpoint to be provisioned in the Compute tab.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b161e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Search Client - Configuration\n",
    "# NOTE: This requires a Vector Search Endpoint provisioned in Databricks\n",
    "\n",
    "vs_endpoint_name = \"my_vector_search_endpoint\"  # Replace with your endpoint name\n",
    "index_name = f\"{catalog_name}.{schema_name}.product_docs_index\"\n",
    "source_table = f\"{catalog_name}.{schema_name}.product_docs\"\n",
    "\n",
    "# Try to import Vector Search client (may not be available on all runtimes)\n",
    "try:\n",
    "    from databricks.vector_search.client import VectorSearchClient\n",
    "    print(\"✅ VectorSearchClient imported successfully\")\n",
    "    print(f\"\\nTo create an index, you would run:\")\n",
    "    print(f\"\"\"\n",
    "vsc = VectorSearchClient()\n",
    "vsc.create_delta_sync_index(\n",
    "    endpoint_name=\"{vs_endpoint_name}\",\n",
    "    source_table_name=\"{source_table}\",\n",
    "    index_name=\"{index_name}\",\n",
    "    pipeline_type=\"TRIGGERED\",\n",
    "    primary_key=\"id\",\n",
    "    embedding_source_column=\"content\",\n",
    "    embedding_model_endpoint_name=\"databricks-gte-large-en\"\n",
    ")\n",
    "    \"\"\")\n",
    "except ImportError as e:\n",
    "    print(f\"VectorSearchClient not available: {e}\")\n",
    "    print(\"\\nThis requires:\")\n",
    "    print(\"  - Databricks Runtime ML 14.3+ or\")\n",
    "    print(\"  - pip install databricks-vectorsearch\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3951cb92",
   "metadata": {},
   "source": [
    "### Example 2.2: Performing a Similarity Search\n",
    "\n",
    "Once indexed, we can ask questions like \"I need a truck for outside\". The system converts this query to a vector and finds the closest match (The Diesel Forklift), even though the word \"truck\" or \"outside\" might not match exactly (it matches \"outdoor\" semantically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of Vector Search Result\n",
    "# In a real scenario, you would query the index:\n",
    "# vsc = VectorSearchClient()\n",
    "# results = vsc.get_index(vs_endpoint_name, index_name).similarity_search(\n",
    "#     query_text=\"I need something for heavy outdoor work\",\n",
    "#     columns=[\"id\", \"content\"],\n",
    "#     num_results=3\n",
    "# )\n",
    "\n",
    "# Here we show what the results would look like:\n",
    "print(\"Query: 'I need something for heavy outdoor work'\")\n",
    "print(\"Top Results (simulated):\\n\")\n",
    "\n",
    "results = [\n",
    "    (2, \"Diesel Titan X: Heavy-duty outdoor forklift. 5-ton capacity...\", 0.89),\n",
    "    (1, \"Electric Forklift 2000: Ideal for indoor warehouse use...\", 0.45),\n",
    "    (3, \"Hand Pallet Jack: Manual tool...\", 0.20)\n",
    "]\n",
    "\n",
    "df_results = spark.createDataFrame(results, [\"id\", \"content\", \"similarity_score\"])\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc3b26",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "| Practice | Description |\n",
    "|----------|-------------|\n",
    "| **Endpoint Management** | Turn off Model Serving endpoints when not in use to control costs |\n",
    "| **Chunking Strategy** | For long documents, split into meaningful chunks (paragraphs, sections) before embedding |\n",
    "| **Embedding Model Selection** | Choose embedding model based on language and domain (e.g., `databricks-gte-large-en` for English) |\n",
    "| **Enable CDF** | Always enable Change Data Feed for tables used with Vector Search |\n",
    "| **RAG Temperature** | Use lower temperature (0.0-0.3) for factual Q&A, higher (0.7-1.0) for creative tasks |\n",
    "| **Prompt Engineering** | Include context and format instructions in prompts for better ai_query results |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25225eb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished\n",
    "| Task | Status |\n",
    "|------|--------|\n",
    "| Explored AI Functions in SQL | ✅ |\n",
    "| Used `ai_analyze_sentiment` and `ai_classify` | ✅ |\n",
    "| Understood Embeddings concept | ✅ |\n",
    "| Learned Vector Search architecture | ✅ |\n",
    "| Created knowledge base for RAG | ✅ |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **AI Functions** democratize AI by allowing SQL-based LLM calls\n",
    "2. **Embeddings** convert text to semantic vectors for similarity search\n",
    "3. **Vector Search** enables meaning-based retrieval at scale\n",
    "4. **RAG** combines retrieval with generation for accurate, grounded AI responses\n",
    "5. Databricks provides managed infrastructure for the entire GenAI stack\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "After this BONUS module, you have a complete foundation in Data Preparation for ML:\n",
    "- Return to core modules if needed for review\n",
    "- Explore Databricks documentation for advanced GenAI features\n",
    "- Consider building a RAG chatbot with your own data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716df8a",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Remove temporary tables and indexes created during this demo. Vector Search indexes should be deleted via the Databricks UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6aa2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: Remove tables created in this notebook\n",
    "# Uncomment and run to clean up resources\n",
    "\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {catalog_name}.{schema_name}.customer_reviews\")\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {catalog_name}.{schema_name}.product_docs\")\n",
    "\n",
    "# Note: Vector Search indexes must be deleted via the Databricks UI or API:\n",
    "# vsc = VectorSearchClient()\n",
    "# vsc.delete_index(endpoint_name=vs_endpoint_name, index_name=index_name)\n",
    "\n",
    "print(\"To clean up, uncomment the DROP TABLE statements above.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
